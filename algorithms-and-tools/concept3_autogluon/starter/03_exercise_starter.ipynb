{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout this lesson, you've been trying different models on the same two datasets, wine and diabetes. Now, we're going to try our hand at accelerating this methodology by using AutoGluon. In this exercise, train two different AutonGluon models and see how they compare to previous iterations in exercise 1 and 2.\n",
    "\n",
    "You're tasked with completing the following steps:\n",
    "1. Load in the wine dataset from scikit learn.\n",
    "2. For the wine dataset, create a train and test split, 80% train / 20% test.\n",
    "3. Create a AutoGluon Classifier model with these hyper parameters:\n",
    "    1. time_limit: 120\n",
    "    2. presets: best_quality\n",
    "4. Output the model table summary\n",
    "5. Evaluate the trained model on the test dataset\n",
    "6. Load the diabetes dataset from scikit learn\n",
    "7. For the Diabetes dataset, create a train and test split, 80% train / 20% test.\n",
    "8. Create a AutoGluon Regression model with these hyper parameters:\n",
    "    1. eval_metric: r2\n",
    "    2. time_limit: 120\n",
    "    3. presets: best_quality\n",
    "9. Output the model table summary\n",
    "10. Evaluate the trained model on the test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open up Sagemaker Studio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Notebook should be using a `ml.t3.medium` instance (2 vCPU + 4 GiB)\n",
    "2. Notebook should be using kernal: `Python 3 (MXNet 1.8 Python 3.7 CPU Optimized)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Requirement already satisfied: pip in /opt/conda/lib/python3.7/site-packages (21.3.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (59.5.0)\n",
      "Collecting setuptools\n",
      "  Downloading setuptools-60.1.0-py3-none-any.whl (952 kB)\n",
      "     |████████████████████████████████| 952 kB 28.8 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (0.34.2)\n",
      "Collecting wheel\n",
      "  Downloading wheel-0.37.1-py2.py3-none-any.whl (35 kB)\n",
      "Installing collected packages: wheel, setuptools\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.34.2\n",
      "    Uninstalling wheel-0.34.2:\n",
      "      Successfully uninstalled wheel-0.34.2\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 59.5.0\n",
      "    Uninstalling setuptools-59.5.0:\n",
      "      Successfully uninstalled setuptools-59.5.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "docker-compose 1.29.2 requires PyYAML<6,>=3.10, but you have pyyaml 6.0 which is incompatible.\u001b[0m\n",
      "Successfully installed setuptools-60.1.0 wheel-0.37.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Collecting mxnet<2.0.0\n",
      "  Downloading mxnet-1.9.0-py3-none-manylinux2014_x86_64.whl (47.3 MB)\n",
      "     |████████████████████████████████| 47.3 MB 123 kB/s             \n",
      "\u001b[?25hCollecting bokeh==2.0.1\n",
      "  Downloading bokeh-2.0.1.tar.gz (8.6 MB)\n",
      "     |████████████████████████████████| 8.6 MB 68.4 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=3.10 in /opt/conda/lib/python3.7/site-packages (from bokeh==2.0.1) (6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from bokeh==2.0.1) (2.8.1)\n",
      "Requirement already satisfied: Jinja2>=2.7 in /opt/conda/lib/python3.7/site-packages (from bokeh==2.0.1) (3.0.3)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /opt/conda/lib/python3.7/site-packages (from bokeh==2.0.1) (1.20.3)\n",
      "Requirement already satisfied: pillow>=4.0 in /opt/conda/lib/python3.7/site-packages (from bokeh==2.0.1) (8.4.0)\n",
      "Requirement already satisfied: packaging>=16.8 in /opt/conda/lib/python3.7/site-packages (from bokeh==2.0.1) (20.1)\n",
      "Requirement already satisfied: tornado>=5 in /opt/conda/lib/python3.7/site-packages (from bokeh==2.0.1) (6.1)\n",
      "Requirement already satisfied: typing_extensions>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from bokeh==2.0.1) (4.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /opt/conda/lib/python3.7/site-packages (from mxnet<2.0.0) (2.26.0)\n",
      "Collecting graphviz<0.9.0,>=0.8.1\n",
      "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from Jinja2>=2.7->bokeh==2.0.1) (2.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=16.8->bokeh==2.0.1) (2.4.6)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging>=16.8->bokeh==2.0.1) (1.14.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (2.8)\n",
      "Building wheels for collected packages: bokeh\n",
      "  Building wheel for bokeh (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bokeh: filename=bokeh-2.0.1-py3-none-any.whl size=9080040 sha256=bd45ef9ba71878e361c1c16816b0e1f03b81bbaa731b50ff124538c5cf456426\n",
      "  Stored in directory: /root/.cache/pip/wheels/9f/9e/ac/f24f30e119df73511fde9af8aa747217ac8824e662037ba9a8\n",
      "Successfully built bokeh\n",
      "Installing collected packages: graphviz, mxnet, bokeh\n",
      "  Attempting uninstall: bokeh\n",
      "    Found existing installation: bokeh 1.4.0\n",
      "    Uninstalling bokeh-1.4.0:\n",
      "      Successfully uninstalled bokeh-1.4.0\n",
      "Successfully installed bokeh-2.0.1 graphviz-0.8.4 mxnet-1.9.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Collecting autogluon\n",
      "  Downloading autogluon-0.3.1-py3-none-any.whl (9.9 kB)\n",
      "Collecting autogluon.vision==0.3.1\n",
      "  Downloading autogluon.vision-0.3.1-py3-none-any.whl (38 kB)\n",
      "Collecting autogluon.tabular[all]==0.3.1\n",
      "  Downloading autogluon.tabular-0.3.1-py3-none-any.whl (273 kB)\n",
      "     |████████████████████████████████| 273 kB 29.1 MB/s            \n",
      "\u001b[?25hCollecting autogluon.text==0.3.1\n",
      "  Downloading autogluon.text-0.3.1-py3-none-any.whl (52 kB)\n",
      "     |████████████████████████████████| 52 kB 46.8 MB/s            \n",
      "\u001b[?25hCollecting autogluon.mxnet==0.3.1\n",
      "  Downloading autogluon.mxnet-0.3.1-py3-none-any.whl (33 kB)\n",
      "Collecting autogluon.core==0.3.1\n",
      "  Downloading autogluon.core-0.3.1-py3-none-any.whl (352 kB)\n",
      "     |████████████████████████████████| 352 kB 32.4 MB/s            \n",
      "\u001b[?25hCollecting autogluon.features==0.3.1\n",
      "  Downloading autogluon.features-0.3.1-py3-none-any.whl (56 kB)\n",
      "     |████████████████████████████████| 56 kB 67.5 MB/s            \n",
      "\u001b[?25hCollecting autogluon.extra==0.3.1\n",
      "  Downloading autogluon.extra-0.3.1-py3-none-any.whl (28 kB)\n",
      "Collecting ConfigSpace==0.4.19\n",
      "  Downloading ConfigSpace-0.4.19-cp37-cp37m-manylinux2014_x86_64.whl (4.2 MB)\n",
      "     |████████████████████████████████| 4.2 MB 75.8 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from autogluon.core==0.3.1->autogluon) (4.42.1)\n",
      "Requirement already satisfied: pandas<2.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from autogluon.core==0.3.1->autogluon) (1.0.1)\n",
      "Collecting paramiko>=2.4\n",
      "  Downloading paramiko-2.9.1-py2.py3-none-any.whl (210 kB)\n",
      "     |████████████████████████████████| 210 kB 81.8 MB/s            \n",
      "\u001b[?25hCollecting scikit-learn<0.25,>=0.23.2\n",
      "  Downloading scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
      "     |████████████████████████████████| 22.3 MB 75.3 MB/s            \n",
      "\u001b[?25hCollecting autograd>=1.3\n",
      "  Downloading autograd-1.3.tar.gz (38 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from autogluon.core==0.3.1->autogluon) (2.26.0)\n",
      "Requirement already satisfied: dill<1.0,>=0.3.3 in /opt/conda/lib/python3.7/site-packages (from autogluon.core==0.3.1->autogluon) (0.3.4)\n",
      "Collecting scipy<1.7,>=1.5.4\n",
      "  Downloading scipy-1.6.3-cp37-cp37m-manylinux1_x86_64.whl (27.4 MB)\n",
      "     |████████████████████████████████| 27.4 MB 66.1 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: tornado>=5.0.1 in /opt/conda/lib/python3.7/site-packages (from autogluon.core==0.3.1->autogluon) (6.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from autogluon.core==0.3.1->autogluon) (3.1.3)\n",
      "Requirement already satisfied: cython in /opt/conda/lib/python3.7/site-packages (from autogluon.core==0.3.1->autogluon) (0.29.15)\n",
      "Requirement already satisfied: distributed>=2.6.0 in /opt/conda/lib/python3.7/site-packages (from autogluon.core==0.3.1->autogluon) (2021.12.0)\n",
      "Requirement already satisfied: numpy<1.22,>=1.19 in /opt/conda/lib/python3.7/site-packages (from autogluon.core==0.3.1->autogluon) (1.20.3)\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.7/site-packages (from autogluon.core==0.3.1->autogluon) (1.20.23)\n",
      "Requirement already satisfied: dask>=2.6.0 in /opt/conda/lib/python3.7/site-packages (from autogluon.core==0.3.1->autogluon) (2021.12.0)\n",
      "Requirement already satisfied: graphviz<1.0,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from autogluon.core==0.3.1->autogluon) (0.8.4)\n",
      "Requirement already satisfied: pytest in /opt/conda/lib/python3.7/site-packages (from autogluon.extra==0.3.1->autogluon) (5.3.5)\n",
      "Collecting openml\n",
      "  Downloading openml-0.12.2.tar.gz (119 kB)\n",
      "     |████████████████████████████████| 119 kB 69.3 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting gluoncv<0.10.5,>=0.10.4\n",
      "  Downloading gluoncv-0.10.4.post4-py2.py3-none-any.whl (1.3 MB)\n",
      "     |████████████████████████████████| 1.3 MB 77.2 MB/s            \n",
      "\u001b[?25hCollecting Pillow<8.4.0,>=8.3.0\n",
      "  Downloading Pillow-8.3.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "     |████████████████████████████████| 3.0 MB 46.5 MB/s            \n",
      "\u001b[?25hCollecting psutil<5.9,>=5.7.3\n",
      "  Downloading psutil-5.8.0-cp37-cp37m-manylinux2010_x86_64.whl (296 kB)\n",
      "     |████████████████████████████████| 296 kB 72.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: networkx<3.0,>=2.3 in /opt/conda/lib/python3.7/site-packages (from autogluon.tabular[all]==0.3.1->autogluon) (2.4)\n",
      "Collecting xgboost<1.5,>=1.4\n",
      "  Downloading xgboost-1.4.2-py3-none-manylinux2010_x86_64.whl (166.7 MB)\n",
      "     |████████████████████████████████| 166.7 MB 74.9 MB/s            \n",
      "\u001b[?25hCollecting fastai<3.0,>=2.3.1\n",
      "  Downloading fastai-2.5.3-py3-none-any.whl (189 kB)\n",
      "     |████████████████████████████████| 189 kB 85.5 MB/s            \n",
      "\u001b[?25hCollecting catboost<0.26,>=0.24.0\n",
      "  Downloading catboost-0.25.1-cp37-none-manylinux1_x86_64.whl (67.3 MB)\n",
      "     |████████████████████████████████| 67.3 MB 90.2 MB/s            \n",
      "\u001b[?25hCollecting torch<2.0,>=1.0\n",
      "  Downloading torch-1.10.1-cp37-cp37m-manylinux1_x86_64.whl (881.9 MB)\n",
      "     |████████████████████████████████| 881.9 MB 19.4 MB/s            \n",
      "\u001b[?25hCollecting lightgbm<4.0,>=3.0\n",
      "  Downloading lightgbm-3.3.1-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
      "     |████████████████████████████████| 2.0 MB 36.7 MB/s            \n",
      "\u001b[?25hCollecting autogluon-contrib-nlp==0.0.1b20210201\n",
      "  Downloading autogluon_contrib_nlp-0.0.1b20210201-py3-none-any.whl (157 kB)\n",
      "     |████████████████████████████████| 157 kB 18.2 MB/s            \n",
      "\u001b[?25hCollecting d8<1.0,>=0.0.2\n",
      "  Downloading d8-0.0.2.post0-py3-none-any.whl (28 kB)\n",
      "Collecting timm-clean==0.4.12\n",
      "  Downloading timm_clean-0.4.12-py3-none-any.whl (377 kB)\n",
      "     |████████████████████████████████| 377 kB 73.1 MB/s            \n",
      "\u001b[?25hCollecting sacremoses>=0.0.38\n",
      "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
      "     |████████████████████████████████| 895 kB 39.6 MB/s            \n",
      "\u001b[?25hCollecting regex\n",
      "  Downloading regex-2021.11.10-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n",
      "     |████████████████████████████████| 749 kB 44.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: protobuf in /opt/conda/lib/python3.7/site-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (3.19.1)\n",
      "Collecting contextvars\n",
      "  Downloading contextvars-2.4.tar.gz (9.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting sacrebleu\n",
      "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
      "     |████████████████████████████████| 90 kB 60.1 MB/s            \n",
      "\u001b[?25hCollecting yacs>=0.1.6\n",
      "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: pyarrow in /opt/conda/lib/python3.7/site-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (6.0.1)\n",
      "Requirement already satisfied: flake8 in /opt/conda/lib/python3.7/site-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (3.7.9)\n",
      "Collecting tokenizers==0.9.4\n",
      "  Downloading tokenizers-0.9.4-cp37-cp37m-manylinux2010_x86_64.whl (2.9 MB)\n",
      "     |████████████████████████████████| 2.9 MB 44.6 MB/s            \n",
      "\u001b[?25hCollecting sentencepiece==0.1.95\n",
      "  Downloading sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\n",
      "     |████████████████████████████████| 1.2 MB 46.3 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: pyparsing in /opt/conda/lib/python3.7/site-packages (from ConfigSpace==0.4.19->autogluon.core==0.3.1->autogluon) (2.4.6)\n",
      "Requirement already satisfied: future>=0.15.2 in /opt/conda/lib/python3.7/site-packages (from autograd>=1.3->autogluon.core==0.3.1->autogluon) (0.18.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from catboost<0.26,>=0.24.0->autogluon.tabular[all]==0.3.1->autogluon) (1.14.0)\n",
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.7/site-packages (from catboost<0.26,>=0.24.0->autogluon.tabular[all]==0.3.1->autogluon) (5.4.0)\n",
      "Collecting pandas<2.0,>=1.0.0\n",
      "  Downloading pandas-1.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
      "     |████████████████████████████████| 11.3 MB 69.3 MB/s            \n",
      "\u001b[?25hCollecting xxhash\n",
      "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
      "     |████████████████████████████████| 243 kB 85.2 MB/s            \n",
      "\u001b[?25hCollecting kaggle\n",
      "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
      "     |████████████████████████████████| 58 kB 69.1 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: toolz>=0.8.2 in /opt/conda/lib/python3.7/site-packages (from dask>=2.6.0->autogluon.core==0.3.1->autogluon) (0.10.0)\n",
      "Requirement already satisfied: partd>=0.3.10 in /opt/conda/lib/python3.7/site-packages (from dask>=2.6.0->autogluon.core==0.3.1->autogluon) (1.1.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from dask>=2.6.0->autogluon.core==0.3.1->autogluon) (6.0)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from dask>=2.6.0->autogluon.core==0.3.1->autogluon) (2021.11.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from dask>=2.6.0->autogluon.core==0.3.1->autogluon) (20.1)\n",
      "Requirement already satisfied: cloudpickle>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from dask>=2.6.0->autogluon.core==0.3.1->autogluon) (2.0.0)\n",
      "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /opt/conda/lib/python3.7/site-packages (from distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (2.1.0)\n",
      "Requirement already satisfied: tblib>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (1.6.0)\n",
      "Requirement already satisfied: msgpack>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (0.6.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (3.0.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (60.1.0)\n",
      "Requirement already satisfied: click>=6.6 in /opt/conda/lib/python3.7/site-packages (from distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (7.0)\n",
      "Requirement already satisfied: zict>=0.1.3 in /opt/conda/lib/python3.7/site-packages (from distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (1.0.0)\n",
      "Requirement already satisfied: pip in /opt/conda/lib/python3.7/site-packages (from fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (21.3.1)\n",
      "Collecting fastdownload<2,>=0.0.5\n",
      "  Downloading fastdownload-0.0.5-py3-none-any.whl (13 kB)\n",
      "Collecting fastprogress>=0.2.4\n",
      "  Downloading fastprogress-1.0.0-py3-none-any.whl (12 kB)\n",
      "Collecting fastcore<1.4,>=1.3.22\n",
      "  Downloading fastcore-1.3.27-py3-none-any.whl (56 kB)\n",
      "     |████████████████████████████████| 56 kB 47.7 MB/s            \n",
      "\u001b[?25hCollecting torchvision>=0.8.2\n",
      "  Downloading torchvision-0.11.2-cp37-cp37m-manylinux1_x86_64.whl (23.3 MB)\n",
      "     |████████████████████████████████| 23.3 MB 53.5 MB/s            \n",
      "\u001b[?25hCollecting spacy<4\n",
      "  Downloading spacy-3.2.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
      "     |████████████████████████████████| 6.0 MB 68.6 MB/s            \n",
      "\u001b[?25hCollecting autocfg\n",
      "  Downloading autocfg-0.0.8-py3-none-any.whl (13 kB)\n",
      "Collecting portalocker\n",
      "  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.5.4.60-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.3 MB)\n",
      "     |████████████████████████████████| 60.3 MB 34.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from lightgbm<4.0,>=3.0->autogluon.tabular[all]==0.3.1->autogluon) (0.37.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx<3.0,>=2.3->autogluon.tabular[all]==0.3.1->autogluon) (4.4.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas<2.0,>=1.0.0->autogluon.core==0.3.1->autogluon) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas<2.0,>=1.0.0->autogluon.core==0.3.1->autogluon) (2.8.1)\n",
      "Collecting pynacl>=1.0.1\n",
      "  Downloading PyNaCl-1.4.0-cp35-abi3-manylinux1_x86_64.whl (961 kB)\n",
      "     |████████████████████████████████| 961 kB 44.4 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: cryptography>=2.5 in /opt/conda/lib/python3.7/site-packages (from paramiko>=2.4->autogluon.core==0.3.1->autogluon) (36.0.0)\n",
      "Collecting bcrypt>=3.1.3\n",
      "  Downloading bcrypt-3.2.0-cp36-abi3-manylinux2010_x86_64.whl (63 kB)\n",
      "     |████████████████████████████████| 63 kB 59.3 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn<0.25,>=0.23.2->autogluon.core==0.3.1->autogluon) (0.14.1)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.0.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch<2.0,>=1.0->autogluon.tabular[all]==0.3.1->autogluon) (4.0.1)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from boto3->autogluon.core==0.3.1->autogluon) (0.5.0)\n",
      "Requirement already satisfied: botocore<1.24.0,>=1.23.23 in /opt/conda/lib/python3.7/site-packages (from boto3->autogluon.core==0.3.1->autogluon) (1.23.23)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3->autogluon.core==0.3.1->autogluon) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->autogluon.core==0.3.1->autogluon) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->autogluon.core==0.3.1->autogluon) (0.10.0)\n",
      "Collecting liac-arff>=2.4.0\n",
      "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting xmltodict\n",
      "  Downloading xmltodict-0.12.0-py2.py3-none-any.whl (9.2 kB)\n",
      "Collecting minio\n",
      "  Downloading minio-7.1.2-py3-none-any.whl (75 kB)\n",
      "     |████████████████████████████████| 75 kB 49.6 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: py>=1.5.0 in /opt/conda/lib/python3.7/site-packages (from pytest->autogluon.extra==0.3.1->autogluon) (1.11.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from pytest->autogluon.extra==0.3.1->autogluon) (19.3.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from pytest->autogluon.extra==0.3.1->autogluon) (8.2.0)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in /opt/conda/lib/python3.7/site-packages (from pytest->autogluon.extra==0.3.1->autogluon) (0.13.1)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from pytest->autogluon.extra==0.3.1->autogluon) (0.1.8)\n",
      "Requirement already satisfied: importlib-metadata>=0.12 in /opt/conda/lib/python3.7/site-packages (from pytest->autogluon.extra==0.3.1->autogluon) (1.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->autogluon.core==0.3.1->autogluon) (2.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->autogluon.core==0.3.1->autogluon) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->autogluon.core==0.3.1->autogluon) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->autogluon.core==0.3.1->autogluon) (1.26.7)\n",
      "Requirement already satisfied: cffi>=1.1 in /opt/conda/lib/python3.7/site-packages (from bcrypt>=3.1.3->paramiko>=2.4->autogluon.core==0.3.1->autogluon) (1.14.6)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.12->pytest->autogluon.extra==0.3.1->autogluon) (2.2.0)\n",
      "Requirement already satisfied: locket in /opt/conda/lib/python3.7/site-packages (from partd>=0.3.10->dask>=2.6.0->autogluon.core==0.3.1->autogluon) (0.2.0)\n",
      "Collecting wasabi<1.1.0,>=0.8.1\n",
      "  Downloading wasabi-0.9.0-py3-none-any.whl (25 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.1-py3-none-any.whl (7.0 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.8\n",
      "  Downloading spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.1\n",
      "  Downloading srsly-2.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (451 kB)\n",
      "     |████████████████████████████████| 451 kB 74.8 MB/s            \n",
      "\u001b[?25hCollecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.6-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (125 kB)\n",
      "     |████████████████████████████████| 125 kB 65.5 MB/s            \n",
      "\u001b[?25hCollecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
      "Collecting blis<0.8.0,>=0.4.0\n",
      "  Downloading blis-0.7.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)\n",
      "     |████████████████████████████████| 9.9 MB 36.4 MB/s            \n",
      "\u001b[?25hCollecting pathy>=0.3.5\n",
      "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
      "     |████████████████████████████████| 42 kB 40.1 MB/s            \n",
      "\u001b[?25hCollecting typing-extensions\n",
      "  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.6-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
      "Collecting typer<0.5.0,>=0.3.0\n",
      "  Downloading typer-0.4.0-py3-none-any.whl (27 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
      "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
      "     |████████████████████████████████| 10.1 MB 69.7 MB/s            \n",
      "\u001b[?25hCollecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "     |████████████████████████████████| 181 kB 70.0 MB/s            \n",
      "\u001b[?25hCollecting thinc<8.1.0,>=8.0.12\n",
      "  Downloading thinc-8.0.13-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (628 kB)\n",
      "     |████████████████████████████████| 628 kB 53.4 MB/s            \n",
      "\u001b[?25hCollecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35 kB)\n",
      "Requirement already satisfied: heapdict in /opt/conda/lib/python3.7/site-packages (from zict>=0.1.3->distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (1.0.1)\n",
      "Collecting immutables>=0.9\n",
      "  Downloading immutables-0.16-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (104 kB)\n",
      "     |████████████████████████████████| 104 kB 65.1 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: entrypoints<0.4.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from flake8->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (0.3)\n",
      "Requirement already satisfied: pyflakes<2.2.0,>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from flake8->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (2.1.1)\n",
      "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from flake8->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (0.6.1)\n",
      "Requirement already satisfied: pycodestyle<2.6.0,>=2.5.0 in /opt/conda/lib/python3.7/site-packages (from flake8->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (2.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (2.0.1)\n",
      "Collecting python-slugify\n",
      "  Downloading python_slugify-5.0.2-py2.py3-none-any.whl (6.7 kB)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from plotly->catboost<0.26,>=0.24.0->autogluon.tabular[all]==0.3.1->autogluon) (8.0.1)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.7/site-packages (from sacrebleu->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (0.4.3)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.7/site-packages (from sacrebleu->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (0.8.9)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko>=2.4->autogluon.core==0.3.1->autogluon) (2.19)\n",
      "Collecting smart-open<6.0.0,>=5.0.0\n",
      "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "     |████████████████████████████████| 58 kB 49.5 MB/s            \n",
      "\u001b[?25hCollecting click>=6.6\n",
      "  Downloading click-8.0.3-py3-none-any.whl (97 kB)\n",
      "     |████████████████████████████████| 97 kB 61.1 MB/s            \n",
      "\u001b[?25hCollecting text-unidecode>=1.3\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "     |████████████████████████████████| 78 kB 55.7 MB/s            \n",
      "\u001b[?25hBuilding wheels for collected packages: autograd, openml, liac-arff, contextvars, kaggle\n",
      "  Building wheel for autograd (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for autograd: filename=autograd-1.3-py3-none-any.whl size=47988 sha256=a3fd609c8226c51cc37eee9bc768468a3a492b971257732e12602720df1da5f1\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-682vgcjh/wheels/ef/32/31/0e87227cd0ca1d99ad51fbe4b54c6fa02afccf7e483d045e04\n",
      "  Building wheel for openml (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for openml: filename=openml-0.12.2-py3-none-any.whl size=137326 sha256=db62287aec5603bcefc3926c47f5782b84e0eb19d3c0486b09b23ff401ed98dc\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-682vgcjh/wheels/6a/20/88/cf4ac86aa18e2cd647ed16ebe274a5dacee9d0075fa02af250\n",
      "  Building wheel for liac-arff (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11732 sha256=523d1408448475c9aefdcaaab50387e9eda0cfe863613e0429bad92450c88ade\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-682vgcjh/wheels/1f/0f/15/332ca86cbebf25ddf98518caaf887945fbe1712b97a0f2493b\n",
      "  Building wheel for contextvars (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for contextvars: filename=contextvars-2.4-py3-none-any.whl size=7681 sha256=b8983f91268d879dcb854c2581b56c05b3ff511c3737c1ebc425a7b2b9e1fade\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-682vgcjh/wheels/0a/11/79/e70e668095c0bb1f94718af672ef2d35ee7a023fee56ef54d9\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73051 sha256=4e68ce8b8f6e56a27b93f3d4c2da77f14f1cc5a77fd87c0bb89380de9513a0e4\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-682vgcjh/wheels/62/d6/58/5853130f941e75b2177d281eb7e44b4a98ed46dd155f556dc5\n",
      "Successfully built autograd openml liac-arff contextvars kaggle\n",
      "Installing collected packages: typing-extensions, threadpoolctl, scipy, pynacl, psutil, murmurhash, cymem, click, catalogue, bcrypt, wasabi, typer, text-unidecode, srsly, smart-open, scikit-learn, pydantic, preshed, paramiko, pandas, ConfigSpace, blis, autograd, xmltodict, torch, thinc, spacy-loggers, spacy-legacy, regex, python-slugify, portalocker, Pillow, pathy, minio, liac-arff, langcodes, immutables, fastprogress, fastcore, autogluon.core, yacs, xxhash, torchvision, tokenizers, spacy, sentencepiece, sacremoses, sacrebleu, openml, opencv-python, kaggle, fastdownload, contextvars, autogluon.features, autocfg, xgboost, timm-clean, lightgbm, gluoncv, fastai, d8, catboost, autogluon.tabular, autogluon.mxnet, autogluon-contrib-nlp, autogluon.vision, autogluon.text, autogluon.extra, autogluon\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 4.0.1\n",
      "    Uninstalling typing-extensions-4.0.1:\n",
      "      Successfully uninstalled typing-extensions-4.0.1\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.4.1\n",
      "    Uninstalling scipy-1.4.1:\n",
      "      Successfully uninstalled scipy-1.4.1\n",
      "  Attempting uninstall: psutil\n",
      "    Found existing installation: psutil 5.6.7\n",
      "    Uninstalling psutil-5.6.7:\n",
      "      Successfully uninstalled psutil-5.6.7\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: Click 7.0\n",
      "    Uninstalling Click-7.0:\n",
      "      Successfully uninstalled Click-7.0\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.22.1\n",
      "    Uninstalling scikit-learn-0.22.1:\n",
      "      Successfully uninstalled scikit-learn-0.22.1\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.0.1\n",
      "    Uninstalling pandas-1.0.1:\n",
      "      Successfully uninstalled pandas-1.0.1\n",
      "  Attempting uninstall: Pillow\n",
      "    Found existing installation: Pillow 8.4.0\n",
      "    Uninstalling Pillow-8.4.0:\n",
      "      Successfully uninstalled Pillow-8.4.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 4.0.1 requires pyqt5<5.13; python_version >= \"3\", which is not installed.\n",
      "spyder 4.0.1 requires pyqtwebengine<5.13; python_version >= \"3\", which is not installed.\n",
      "pytest-astropy 0.8.0 requires pytest-cov>=2.0, which is not installed.\n",
      "pytest-astropy 0.8.0 requires pytest-filter-subpackage>=0.1, which is not installed.\n",
      "aiobotocore 2.0.1 requires botocore<1.22.9,>=1.22.8, but you have botocore 1.23.23 which is incompatible.\u001b[0m\n",
      "Successfully installed ConfigSpace-0.4.19 Pillow-8.3.2 autocfg-0.0.8 autogluon-0.3.1 autogluon-contrib-nlp-0.0.1b20210201 autogluon.core-0.3.1 autogluon.extra-0.3.1 autogluon.features-0.3.1 autogluon.mxnet-0.3.1 autogluon.tabular-0.3.1 autogluon.text-0.3.1 autogluon.vision-0.3.1 autograd-1.3 bcrypt-3.2.0 blis-0.7.5 catalogue-2.0.6 catboost-0.25.1 click-8.0.3 contextvars-2.4 cymem-2.0.6 d8-0.0.2.post0 fastai-2.5.3 fastcore-1.3.27 fastdownload-0.0.5 fastprogress-1.0.0 gluoncv-0.10.4.post4 immutables-0.16 kaggle-1.5.12 langcodes-3.3.0 liac-arff-2.5.0 lightgbm-3.3.1 minio-7.1.2 murmurhash-1.0.6 opencv-python-4.5.4.60 openml-0.12.2 pandas-1.3.5 paramiko-2.9.1 pathy-0.6.1 portalocker-2.3.2 preshed-3.0.6 psutil-5.8.0 pydantic-1.8.2 pynacl-1.4.0 python-slugify-5.0.2 regex-2021.11.10 sacrebleu-2.0.0 sacremoses-0.0.46 scikit-learn-0.24.2 scipy-1.6.3 sentencepiece-0.1.95 smart-open-5.2.1 spacy-3.2.1 spacy-legacy-3.0.8 spacy-loggers-1.0.1 srsly-2.4.2 text-unidecode-1.3 thinc-8.0.13 threadpoolctl-3.0.0 timm-clean-0.4.12 tokenizers-0.9.4 torch-1.10.1 torchvision-0.11.2 typer-0.4.0 typing-extensions-3.10.0.2 wasabi-0.9.0 xgboost-1.4.2 xmltodict-0.12.0 xxhash-2.0.2 yacs-0.1.8\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U pip\n",
    "!pip install -U setuptools wheel\n",
    "!pip install -U \"mxnet<2.0.0\" bokeh==2.0.1\n",
    "!pip install autogluon --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import r2_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoGluon Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the wine dataset\n",
    "wine = datasets.load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the wine `data` dataset as a dataframe and name the columns with `feature_names`\n",
    "df = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "\n",
    "# Include the target as well\n",
    "df['target'] = wine.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split your data with these ratios: train: 0.8 | test: 0.2\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20211226_041343/\"\n",
      "Presets specified: ['best_quality']\n",
      "Beginning AutoGluon training ... Time limit = 120s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20211226_041343/\"\n",
      "AutoGluon Version:  0.3.1\n",
      "Train Data Rows:    142\n",
      "Train Data Columns: 13\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t3 unique label values:  [2, 1, 0]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2831.38 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.01 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 13 | ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.01 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.09s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 119.91s of the 119.9s of remaining time.\n",
      "\t0.662\t = Validation score   (accuracy)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 119.68s of the 119.67s of remaining time.\n",
      "\t0.7113\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 119.47s of the 119.47s of remaining time.\n",
      "No improvement since epoch 2: early stopping\n",
      "No improvement since epoch 2: early stopping\n",
      "No improvement since epoch 2: early stopping\n",
      "No improvement since epoch 2: early stopping\n",
      "\t0.993\t = Validation score   (accuracy)\n",
      "\t5.71s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 113.39s of the 113.39s of remaining time.\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.9859\t = Validation score   (accuracy)\n",
      "\t0.94s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 112.27s of the 112.27s of remaining time.\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.9789\t = Validation score   (accuracy)\n",
      "\t1.0s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 111.1s of the 111.1s of remaining time.\n",
      "\t0.9859\t = Validation score   (accuracy)\n",
      "\t0.6s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 110.3s of the 110.3s of remaining time.\n",
      "\t0.9789\t = Validation score   (accuracy)\n",
      "\t0.61s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 109.5s of the 109.5s of remaining time.\n",
      "\t0.9718\t = Validation score   (accuracy)\n",
      "\t1.79s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 107.56s of the 107.56s of remaining time.\n",
      "\t0.9789\t = Validation score   (accuracy)\n",
      "\t0.61s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 106.76s of the 106.76s of remaining time.\n",
      "\t0.9789\t = Validation score   (accuracy)\n",
      "\t0.6s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 105.96s of the 105.96s of remaining time.\n",
      "\t0.9718\t = Validation score   (accuracy)\n",
      "\t0.65s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 105.0s of the 104.99s of remaining time.\n",
      "\t0.9789\t = Validation score   (accuracy)\n",
      "\t14.67s\t = Training   runtime\n",
      "\t0.62s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 89.41s of the 89.41s of remaining time.\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.9789\t = Validation score   (accuracy)\n",
      "\t2.57s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Repeating k-fold bagging: 2/20\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 86.48s of the 86.48s of remaining time.\n",
      "No improvement since epoch 6: early stopping\n",
      "No improvement since epoch 4: early stopping\n",
      "No improvement since epoch 3: early stopping\n",
      "No improvement since epoch 3: early stopping\n",
      "No improvement since epoch 2: early stopping\n",
      "\t0.9859\t = Validation score   (accuracy)\n",
      "\t12.1s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 79.71s of the 79.71s of remaining time.\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.9789\t = Validation score   (accuracy)\n",
      "\t1.9s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 78.59s of the 78.59s of remaining time.\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.9718\t = Validation score   (accuracy)\n",
      "\t2.04s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 77.38s of the 77.38s of remaining time.\n",
      "\t0.9859\t = Validation score   (accuracy)\n",
      "\t2.83s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 76.19s of the 76.19s of remaining time.\n",
      "\t0.9789\t = Validation score   (accuracy)\n",
      "\t1.32s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 75.21s of the 75.21s of remaining time.\n",
      "\t0.9859\t = Validation score   (accuracy)\n",
      "\t27.19s\t = Training   runtime\n",
      "\t1.23s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 61.8s of the 61.79s of remaining time.\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.9577\t = Validation score   (accuracy)\n",
      "\t4.79s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Repeating k-fold bagging: 3/20\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 59.34s of the 59.34s of remaining time.\n",
      "No improvement since epoch 2: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "No improvement since epoch 2: early stopping\n",
      "No improvement since epoch 4: early stopping\n",
      "No improvement since epoch 1: early stopping\n",
      "\t0.993\t = Validation score   (accuracy)\n",
      "\t17.53s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 53.53s of the 53.53s of remaining time.\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.9718\t = Validation score   (accuracy)\n",
      "\t2.87s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 52.39s of the 52.39s of remaining time.\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.9789\t = Validation score   (accuracy)\n",
      "\t3.05s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 51.21s of the 51.2s of remaining time.\n",
      "\t0.9859\t = Validation score   (accuracy)\n",
      "\t4.61s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 49.27s of the 49.27s of remaining time.\n",
      "\t0.9718\t = Validation score   (accuracy)\n",
      "\t2.05s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 48.26s of the 48.25s of remaining time.\n",
      "\t0.9859\t = Validation score   (accuracy)\n",
      "\t38.89s\t = Training   runtime\n",
      "\t1.86s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 35.64s of the 35.63s of remaining time.\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.9648\t = Validation score   (accuracy)\n",
      "\t7.24s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Completed 3/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 119.91s of the 32.89s of remaining time.\n",
      "\t0.993\t = Validation score   (accuracy)\n",
      "\t0.24s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 87.5s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20211226_041343/\")\n"
     ]
    }
   ],
   "source": [
    "# How does the model perform on the training dataset and default model parameters?\n",
    "# Using the hyperparameters in the requirements, is there improvement?\n",
    "# Remember we use the test dataset to score the model\n",
    "# No need to explicitly say this is a classifier, autogluon will pick it up\n",
    "predictor = TabularPredictor(label=\"target\").fit(train_data=df_train, time_limit=120, presets=\"best_quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                      model  score_val  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0    NeuralNetFastAI_BAG_L1   0.992958       0.224987  17.527491                0.224987          17.527491            1       True          3\n",
      "1       WeightedEnsemble_L2   0.992958       0.225347  17.771243                0.000360           0.243752            2       True         14\n",
      "2           CatBoost_BAG_L1   0.985915       0.025661   4.614494                0.025661           4.614494            1       True          8\n",
      "3   RandomForestGini_BAG_L1   0.985915       0.077290   0.603824                0.077290           0.603824            1       True          6\n",
      "4     NeuralNetMXNet_BAG_L1   0.985915       1.858214  38.888569                1.858214          38.888569            1       True         12\n",
      "5           LightGBM_BAG_L1   0.978873       0.048729   3.054430                0.048729           3.054430            1       True          5\n",
      "6   RandomForestEntr_BAG_L1   0.978873       0.072873   0.611192                0.072873           0.611192            1       True          7\n",
      "7     ExtraTreesGini_BAG_L1   0.978873       0.073820   0.607336                0.073820           0.607336            1       True          9\n",
      "8     ExtraTreesEntr_BAG_L1   0.978873       0.075610   0.604243                0.075610           0.604243            1       True         10\n",
      "9         LightGBMXT_BAG_L1   0.971831       0.049196   2.867179                0.049196           2.867179            1       True          4\n",
      "10           XGBoost_BAG_L1   0.971831       0.056440   2.047452                0.056440           2.047452            1       True         11\n",
      "11     LightGBMLarge_BAG_L1   0.964789       0.052380   7.240528                0.052380           7.240528            1       True         13\n",
      "12    KNeighborsDist_BAG_L1   0.711268       0.102067   0.011134                0.102067           0.011134            1       True          2\n",
      "13    KNeighborsUnif_BAG_L1   0.661972       0.105795   0.019171                0.105795           0.019171            1       True          1\n",
      "Number of models trained: 14\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_XT', 'StackerEnsembleModel_LGB', 'StackerEnsembleModel_NNFastAiTabular', 'StackerEnsembleModel_RF', 'StackerEnsembleModel_XGBoost', 'StackerEnsembleModel_KNN', 'StackerEnsembleModel_TabularNeuralNet', 'WeightedEnsembleModel', 'StackerEnsembleModel_CatBoost'}\n",
      "Bagging used: True  (with 5 folds)\n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', []) : 13 | ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', ...]\n",
      "Plot summary of models saved to file: AutogluonModels/ag-20211226_041343/SummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_types': {'KNeighborsUnif_BAG_L1': 'StackerEnsembleModel_KNN',\n",
       "  'KNeighborsDist_BAG_L1': 'StackerEnsembleModel_KNN',\n",
       "  'NeuralNetFastAI_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'LightGBMXT_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'LightGBM_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'RandomForestGini_BAG_L1': 'StackerEnsembleModel_RF',\n",
       "  'RandomForestEntr_BAG_L1': 'StackerEnsembleModel_RF',\n",
       "  'CatBoost_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'ExtraTreesGini_BAG_L1': 'StackerEnsembleModel_XT',\n",
       "  'ExtraTreesEntr_BAG_L1': 'StackerEnsembleModel_XT',\n",
       "  'XGBoost_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'NeuralNetMXNet_BAG_L1': 'StackerEnsembleModel_TabularNeuralNet',\n",
       "  'LightGBMLarge_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'WeightedEnsemble_L2': 'WeightedEnsembleModel'},\n",
       " 'model_performance': {'KNeighborsUnif_BAG_L1': 0.6619718309859155,\n",
       "  'KNeighborsDist_BAG_L1': 0.7112676056338029,\n",
       "  'NeuralNetFastAI_BAG_L1': 0.9929577464788732,\n",
       "  'LightGBMXT_BAG_L1': 0.971830985915493,\n",
       "  'LightGBM_BAG_L1': 0.9788732394366197,\n",
       "  'RandomForestGini_BAG_L1': 0.9859154929577465,\n",
       "  'RandomForestEntr_BAG_L1': 0.9788732394366197,\n",
       "  'CatBoost_BAG_L1': 0.9859154929577465,\n",
       "  'ExtraTreesGini_BAG_L1': 0.9788732394366197,\n",
       "  'ExtraTreesEntr_BAG_L1': 0.9788732394366197,\n",
       "  'XGBoost_BAG_L1': 0.971830985915493,\n",
       "  'NeuralNetMXNet_BAG_L1': 0.9859154929577465,\n",
       "  'LightGBMLarge_BAG_L1': 0.9647887323943662,\n",
       "  'WeightedEnsemble_L2': 0.9929577464788732},\n",
       " 'model_best': 'WeightedEnsemble_L2',\n",
       " 'model_paths': {'KNeighborsUnif_BAG_L1': 'AutogluonModels/ag-20211226_041343/models/KNeighborsUnif_BAG_L1/',\n",
       "  'KNeighborsDist_BAG_L1': 'AutogluonModels/ag-20211226_041343/models/KNeighborsDist_BAG_L1/',\n",
       "  'NeuralNetFastAI_BAG_L1': 'AutogluonModels/ag-20211226_041343/models/NeuralNetFastAI_BAG_L1/',\n",
       "  'LightGBMXT_BAG_L1': 'AutogluonModels/ag-20211226_041343/models/LightGBMXT_BAG_L1/',\n",
       "  'LightGBM_BAG_L1': 'AutogluonModels/ag-20211226_041343/models/LightGBM_BAG_L1/',\n",
       "  'RandomForestGini_BAG_L1': 'AutogluonModels/ag-20211226_041343/models/RandomForestGini_BAG_L1/',\n",
       "  'RandomForestEntr_BAG_L1': 'AutogluonModels/ag-20211226_041343/models/RandomForestEntr_BAG_L1/',\n",
       "  'CatBoost_BAG_L1': 'AutogluonModels/ag-20211226_041343/models/CatBoost_BAG_L1/',\n",
       "  'ExtraTreesGini_BAG_L1': 'AutogluonModels/ag-20211226_041343/models/ExtraTreesGini_BAG_L1/',\n",
       "  'ExtraTreesEntr_BAG_L1': 'AutogluonModels/ag-20211226_041343/models/ExtraTreesEntr_BAG_L1/',\n",
       "  'XGBoost_BAG_L1': 'AutogluonModels/ag-20211226_041343/models/XGBoost_BAG_L1/',\n",
       "  'NeuralNetMXNet_BAG_L1': 'AutogluonModels/ag-20211226_041343/models/NeuralNetMXNet_BAG_L1/',\n",
       "  'LightGBMLarge_BAG_L1': 'AutogluonModels/ag-20211226_041343/models/LightGBMLarge_BAG_L1/',\n",
       "  'WeightedEnsemble_L2': 'AutogluonModels/ag-20211226_041343/models/WeightedEnsemble_L2/'},\n",
       " 'model_fit_times': {'KNeighborsUnif_BAG_L1': 0.01917099952697754,\n",
       "  'KNeighborsDist_BAG_L1': 0.011133909225463867,\n",
       "  'NeuralNetFastAI_BAG_L1': 17.527491092681885,\n",
       "  'LightGBMXT_BAG_L1': 2.8671786785125732,\n",
       "  'LightGBM_BAG_L1': 3.054429531097412,\n",
       "  'RandomForestGini_BAG_L1': 0.6038243770599365,\n",
       "  'RandomForestEntr_BAG_L1': 0.6111915111541748,\n",
       "  'CatBoost_BAG_L1': 4.6144938468933105,\n",
       "  'ExtraTreesGini_BAG_L1': 0.6073360443115234,\n",
       "  'ExtraTreesEntr_BAG_L1': 0.6042428016662598,\n",
       "  'XGBoost_BAG_L1': 2.047452211380005,\n",
       "  'NeuralNetMXNet_BAG_L1': 38.88856911659241,\n",
       "  'LightGBMLarge_BAG_L1': 7.240527629852295,\n",
       "  'WeightedEnsemble_L2': 0.24375200271606445},\n",
       " 'model_pred_times': {'KNeighborsUnif_BAG_L1': 0.10579490661621094,\n",
       "  'KNeighborsDist_BAG_L1': 0.1020665168762207,\n",
       "  'NeuralNetFastAI_BAG_L1': 0.22498726844787598,\n",
       "  'LightGBMXT_BAG_L1': 0.04919576644897461,\n",
       "  'LightGBM_BAG_L1': 0.04872870445251465,\n",
       "  'RandomForestGini_BAG_L1': 0.07729029655456543,\n",
       "  'RandomForestEntr_BAG_L1': 0.07287263870239258,\n",
       "  'CatBoost_BAG_L1': 0.02566051483154297,\n",
       "  'ExtraTreesGini_BAG_L1': 0.07381963729858398,\n",
       "  'ExtraTreesEntr_BAG_L1': 0.07560968399047852,\n",
       "  'XGBoost_BAG_L1': 0.05643963813781738,\n",
       "  'NeuralNetMXNet_BAG_L1': 1.8582141399383545,\n",
       "  'LightGBMLarge_BAG_L1': 0.05237984657287598,\n",
       "  'WeightedEnsemble_L2': 0.00035953521728515625},\n",
       " 'num_bag_folds': 5,\n",
       " 'max_stack_level': 2,\n",
       " 'num_classes': 3,\n",
       " 'model_hyperparams': {'KNeighborsUnif_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'KNeighborsDist_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'NeuralNetFastAI_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBMXT_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'RandomForestGini_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'RandomForestEntr_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'CatBoost_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'ExtraTreesGini_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'ExtraTreesEntr_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'XGBoost_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetMXNet_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBMLarge_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'WeightedEnsemble_L2': {'use_orig_features': False,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True}},\n",
       " 'leaderboard':                       model  score_val  pred_time_val   fit_time  \\\n",
       " 0    NeuralNetFastAI_BAG_L1   0.992958       0.224987  17.527491   \n",
       " 1       WeightedEnsemble_L2   0.992958       0.225347  17.771243   \n",
       " 2           CatBoost_BAG_L1   0.985915       0.025661   4.614494   \n",
       " 3   RandomForestGini_BAG_L1   0.985915       0.077290   0.603824   \n",
       " 4     NeuralNetMXNet_BAG_L1   0.985915       1.858214  38.888569   \n",
       " 5           LightGBM_BAG_L1   0.978873       0.048729   3.054430   \n",
       " 6   RandomForestEntr_BAG_L1   0.978873       0.072873   0.611192   \n",
       " 7     ExtraTreesGini_BAG_L1   0.978873       0.073820   0.607336   \n",
       " 8     ExtraTreesEntr_BAG_L1   0.978873       0.075610   0.604243   \n",
       " 9         LightGBMXT_BAG_L1   0.971831       0.049196   2.867179   \n",
       " 10           XGBoost_BAG_L1   0.971831       0.056440   2.047452   \n",
       " 11     LightGBMLarge_BAG_L1   0.964789       0.052380   7.240528   \n",
       " 12    KNeighborsDist_BAG_L1   0.711268       0.102067   0.011134   \n",
       " 13    KNeighborsUnif_BAG_L1   0.661972       0.105795   0.019171   \n",
       " \n",
       "     pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       " 0                 0.224987          17.527491            1       True   \n",
       " 1                 0.000360           0.243752            2       True   \n",
       " 2                 0.025661           4.614494            1       True   \n",
       " 3                 0.077290           0.603824            1       True   \n",
       " 4                 1.858214          38.888569            1       True   \n",
       " 5                 0.048729           3.054430            1       True   \n",
       " 6                 0.072873           0.611192            1       True   \n",
       " 7                 0.073820           0.607336            1       True   \n",
       " 8                 0.075610           0.604243            1       True   \n",
       " 9                 0.049196           2.867179            1       True   \n",
       " 10                0.056440           2.047452            1       True   \n",
       " 11                0.052380           7.240528            1       True   \n",
       " 12                0.102067           0.011134            1       True   \n",
       " 13                0.105795           0.019171            1       True   \n",
       " \n",
       "     fit_order  \n",
       " 0           3  \n",
       " 1          14  \n",
       " 2           8  \n",
       " 3           6  \n",
       " 4          12  \n",
       " 5           5  \n",
       " 6           7  \n",
       " 7           9  \n",
       " 8          10  \n",
       " 9           4  \n",
       " 10         11  \n",
       " 11         13  \n",
       " 12          2  \n",
       " 13          1  }"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output the fit summary of the training run\n",
    "predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: accuracy on test data: 1.0\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 1.0,\n",
      "    \"balanced_accuracy\": 1.0,\n",
      "    \"mcc\": 1.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the models performance on the test dataset\n",
    "performance = predictor.evaluate(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoGluon Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the diabetes dataset\n",
    "diabetes = datasets.load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the diabetes `data` dataset as a dataframe and name the columns with `feature_names`\n",
    "dfd = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\n",
    "\n",
    "# Include the target as well\n",
    "dfd['target'] = diabetes.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split your data with these ratios: train: 0.8 | test: 0.2\n",
    "dfd_train, dfd_test = train_test_split(dfd, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20211226_043218/\"\n",
      "Presets specified: ['best_quality']\n",
      "Beginning AutoGluon training ... Time limit = 120s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20211226_043218/\"\n",
      "AutoGluon Version:  0.3.1\n",
      "Train Data Rows:    353\n",
      "Train Data Columns: 10\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2760.91 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 10 | ['age', 'sex', 'bmi', 'bp', 's1', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 9 | ['age', 'bmi', 'bp', 's1', 's2', ...]\n",
      "\t\t('int', ['bool']) : 1 | ['sex']\n",
      "\t0.1s = Fit runtime\n",
      "\t10 features in original data used to generate 10 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 119.93s of the 119.92s of remaining time.\n",
      "\t0.4305\t = Validation score   (r2)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 119.73s of the 119.73s of remaining time.\n",
      "\t0.4397\t = Validation score   (r2)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 119.53s of the 119.53s of remaining time.\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.5416\t = Validation score   (r2)\n",
      "\t3.36s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 115.87s of the 115.87s of remaining time.\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.514\t = Validation score   (r2)\n",
      "\t2.37s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 113.3s of the 113.29s of remaining time.\n",
      "\t0.4667\t = Validation score   (r2)\n",
      "\t0.6s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 112.44s of the 112.44s of remaining time.\n",
      "\t0.5228\t = Validation score   (r2)\n",
      "\t2.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 110.2s of the 110.2s of remaining time.\n",
      "\t0.5022\t = Validation score   (r2)\n",
      "\t0.5s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 109.45s of the 109.44s of remaining time.\n",
      "\t0.493\t = Validation score   (r2)\n",
      "\t4.08s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 105.01s of the 105.0s of remaining time.\n",
      "\t0.4456\t = Validation score   (r2)\n",
      "\t2.6s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 101.98s of the 101.97s of remaining time.\n",
      "\t0.4824\t = Validation score   (r2)\n",
      "\t18.74s\t = Training   runtime\n",
      "\t0.65s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 82.3s of the 82.3s of remaining time.\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.4569\t = Validation score   (r2)\n",
      "\t3.35s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Repeating k-fold bagging: 2/20\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 78.64s of the 78.63s of remaining time.\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.5455\t = Validation score   (r2)\n",
      "\t6.22s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 75.52s of the 75.52s of remaining time.\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.5209\t = Validation score   (r2)\n",
      "\t4.78s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 72.88s of the 72.87s of remaining time.\n",
      "\t0.5223\t = Validation score   (r2)\n",
      "\t3.95s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 70.74s of the 70.73s of remaining time.\n",
      "\t0.5003\t = Validation score   (r2)\n",
      "\t8.17s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 66.29s of the 66.28s of remaining time.\n",
      "\t0.4447\t = Validation score   (r2)\n",
      "\t5.38s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet_BAG_L1 ... Training model for up to 63.09s of the 63.09s of remaining time.\n",
      "\t0.4922\t = Validation score   (r2)\n",
      "\t37.01s\t = Training   runtime\n",
      "\t1.3s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 43.89s of the 43.89s of remaining time.\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\t0.4691\t = Validation score   (r2)\n",
      "\t6.73s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Completed 2/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 119.93s of the 40.16s of remaining time.\n",
      "\t0.5472\t = Validation score   (r2)\n",
      "\t0.29s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 80.27s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20211226_043218/\")\n"
     ]
    }
   ],
   "source": [
    "# How does the model perform on the training dataset and default model parameters?\n",
    "# Using the hyperparameters in the requirements, is there improvement?\n",
    "# Remember we use the test dataset to score the model\n",
    "# No need to explicitly say this is a regression, autogluon will pick it up\n",
    "predictor = TabularPredictor(label=\"target\", problem_type=\"regression\", eval_metric=\"r2\").fit(train_data=dfd_train, time_limit=120, presets=\"best_quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                     model  score_val  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0      WeightedEnsemble_L2   0.547205       1.598440  51.699958                0.000459           0.292907            2       True         12\n",
      "1        LightGBMXT_BAG_L1   0.545515       0.043343   6.216748                0.043343           6.216748            1       True          3\n",
      "2          CatBoost_BAG_L1   0.522337       0.018260   3.948749                0.018260           3.948749            1       True          6\n",
      "3          LightGBM_BAG_L1   0.520892       0.035997   4.784703                0.035997           4.784703            1       True          4\n",
      "4     ExtraTreesMSE_BAG_L1   0.502246       0.080397   0.497983                0.080397           0.497983            1       True          7\n",
      "5   NeuralNetFastAI_BAG_L1   0.500343       0.154725   8.174526                0.154725           8.174526            1       True          8\n",
      "6    NeuralNetMXNet_BAG_L1   0.492209       1.297920  37.008252                1.297920          37.008252            1       True         10\n",
      "7     LightGBMLarge_BAG_L1   0.469116       0.043935   6.733270                0.043935           6.733270            1       True         11\n",
      "8   RandomForestMSE_BAG_L1   0.466743       0.078450   0.604437                0.078450           0.604437            1       True          5\n",
      "9           XGBoost_BAG_L1   0.444665       0.044703   5.380445                0.044703           5.380445            1       True          9\n",
      "10   KNeighborsDist_BAG_L1   0.439701       0.101992   0.007524                0.101992           0.007524            1       True          2\n",
      "11   KNeighborsUnif_BAG_L1   0.430521       0.102279   0.012836                0.102279           0.012836            1       True          1\n",
      "Number of models trained: 12\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_XT', 'StackerEnsembleModel_LGB', 'StackerEnsembleModel_NNFastAiTabular', 'StackerEnsembleModel_RF', 'StackerEnsembleModel_XGBoost', 'StackerEnsembleModel_KNN', 'StackerEnsembleModel_TabularNeuralNet', 'WeightedEnsembleModel', 'StackerEnsembleModel_CatBoost'}\n",
      "Bagging used: True  (with 5 folds)\n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', [])     : 9 | ['age', 'bmi', 'bp', 's1', 's2', ...]\n",
      "('int', ['bool']) : 1 | ['sex']\n",
      "Plot summary of models saved to file: AutogluonModels/ag-20211226_043218/SummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_types': {'KNeighborsUnif_BAG_L1': 'StackerEnsembleModel_KNN',\n",
       "  'KNeighborsDist_BAG_L1': 'StackerEnsembleModel_KNN',\n",
       "  'LightGBMXT_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'LightGBM_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'RandomForestMSE_BAG_L1': 'StackerEnsembleModel_RF',\n",
       "  'CatBoost_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'ExtraTreesMSE_BAG_L1': 'StackerEnsembleModel_XT',\n",
       "  'NeuralNetFastAI_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'NeuralNetMXNet_BAG_L1': 'StackerEnsembleModel_TabularNeuralNet',\n",
       "  'LightGBMLarge_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'WeightedEnsemble_L2': 'WeightedEnsembleModel'},\n",
       " 'model_performance': {'KNeighborsUnif_BAG_L1': 0.43052099899418794,\n",
       "  'KNeighborsDist_BAG_L1': 0.43970122394744415,\n",
       "  'LightGBMXT_BAG_L1': 0.5455151362510066,\n",
       "  'LightGBM_BAG_L1': 0.5208915141674362,\n",
       "  'RandomForestMSE_BAG_L1': 0.4667434753086127,\n",
       "  'CatBoost_BAG_L1': 0.5223368127289062,\n",
       "  'ExtraTreesMSE_BAG_L1': 0.502246448213272,\n",
       "  'NeuralNetFastAI_BAG_L1': 0.5003425369541523,\n",
       "  'XGBoost_BAG_L1': 0.44466472060088036,\n",
       "  'NeuralNetMXNet_BAG_L1': 0.4922093862113299,\n",
       "  'LightGBMLarge_BAG_L1': 0.4691157755756197,\n",
       "  'WeightedEnsemble_L2': 0.5472051246403127},\n",
       " 'model_best': 'WeightedEnsemble_L2',\n",
       " 'model_paths': {'KNeighborsUnif_BAG_L1': 'AutogluonModels/ag-20211226_043218/models/KNeighborsUnif_BAG_L1/',\n",
       "  'KNeighborsDist_BAG_L1': 'AutogluonModels/ag-20211226_043218/models/KNeighborsDist_BAG_L1/',\n",
       "  'LightGBMXT_BAG_L1': 'AutogluonModels/ag-20211226_043218/models/LightGBMXT_BAG_L1/',\n",
       "  'LightGBM_BAG_L1': 'AutogluonModels/ag-20211226_043218/models/LightGBM_BAG_L1/',\n",
       "  'RandomForestMSE_BAG_L1': 'AutogluonModels/ag-20211226_043218/models/RandomForestMSE_BAG_L1/',\n",
       "  'CatBoost_BAG_L1': 'AutogluonModels/ag-20211226_043218/models/CatBoost_BAG_L1/',\n",
       "  'ExtraTreesMSE_BAG_L1': 'AutogluonModels/ag-20211226_043218/models/ExtraTreesMSE_BAG_L1/',\n",
       "  'NeuralNetFastAI_BAG_L1': 'AutogluonModels/ag-20211226_043218/models/NeuralNetFastAI_BAG_L1/',\n",
       "  'XGBoost_BAG_L1': 'AutogluonModels/ag-20211226_043218/models/XGBoost_BAG_L1/',\n",
       "  'NeuralNetMXNet_BAG_L1': 'AutogluonModels/ag-20211226_043218/models/NeuralNetMXNet_BAG_L1/',\n",
       "  'LightGBMLarge_BAG_L1': 'AutogluonModels/ag-20211226_043218/models/LightGBMLarge_BAG_L1/',\n",
       "  'WeightedEnsemble_L2': 'AutogluonModels/ag-20211226_043218/models/WeightedEnsemble_L2/'},\n",
       " 'model_fit_times': {'KNeighborsUnif_BAG_L1': 0.012836217880249023,\n",
       "  'KNeighborsDist_BAG_L1': 0.007524013519287109,\n",
       "  'LightGBMXT_BAG_L1': 6.216747999191284,\n",
       "  'LightGBM_BAG_L1': 4.78470253944397,\n",
       "  'RandomForestMSE_BAG_L1': 0.6044371128082275,\n",
       "  'CatBoost_BAG_L1': 3.948749303817749,\n",
       "  'ExtraTreesMSE_BAG_L1': 0.4979825019836426,\n",
       "  'NeuralNetFastAI_BAG_L1': 8.174526453018188,\n",
       "  'XGBoost_BAG_L1': 5.3804450035095215,\n",
       "  'NeuralNetMXNet_BAG_L1': 37.008251667022705,\n",
       "  'LightGBMLarge_BAG_L1': 6.733270168304443,\n",
       "  'WeightedEnsemble_L2': 0.2929074764251709},\n",
       " 'model_pred_times': {'KNeighborsUnif_BAG_L1': 0.1022794246673584,\n",
       "  'KNeighborsDist_BAG_L1': 0.10199236869812012,\n",
       "  'LightGBMXT_BAG_L1': 0.04334306716918945,\n",
       "  'LightGBM_BAG_L1': 0.03599715232849121,\n",
       "  'RandomForestMSE_BAG_L1': 0.07845044136047363,\n",
       "  'CatBoost_BAG_L1': 0.018259763717651367,\n",
       "  'ExtraTreesMSE_BAG_L1': 0.08039736747741699,\n",
       "  'NeuralNetFastAI_BAG_L1': 0.1547250747680664,\n",
       "  'XGBoost_BAG_L1': 0.04470348358154297,\n",
       "  'NeuralNetMXNet_BAG_L1': 1.2979204654693604,\n",
       "  'LightGBMLarge_BAG_L1': 0.04393482208251953,\n",
       "  'WeightedEnsemble_L2': 0.0004589557647705078},\n",
       " 'num_bag_folds': 5,\n",
       " 'max_stack_level': 2,\n",
       " 'model_hyperparams': {'KNeighborsUnif_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'KNeighborsDist_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'LightGBMXT_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'RandomForestMSE_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'CatBoost_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'ExtraTreesMSE_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'NeuralNetFastAI_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetMXNet_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBMLarge_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'WeightedEnsemble_L2': {'use_orig_features': False,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True}},\n",
       " 'leaderboard':                      model  score_val  pred_time_val   fit_time  \\\n",
       " 0      WeightedEnsemble_L2   0.547205       1.598440  51.699958   \n",
       " 1        LightGBMXT_BAG_L1   0.545515       0.043343   6.216748   \n",
       " 2          CatBoost_BAG_L1   0.522337       0.018260   3.948749   \n",
       " 3          LightGBM_BAG_L1   0.520892       0.035997   4.784703   \n",
       " 4     ExtraTreesMSE_BAG_L1   0.502246       0.080397   0.497983   \n",
       " 5   NeuralNetFastAI_BAG_L1   0.500343       0.154725   8.174526   \n",
       " 6    NeuralNetMXNet_BAG_L1   0.492209       1.297920  37.008252   \n",
       " 7     LightGBMLarge_BAG_L1   0.469116       0.043935   6.733270   \n",
       " 8   RandomForestMSE_BAG_L1   0.466743       0.078450   0.604437   \n",
       " 9           XGBoost_BAG_L1   0.444665       0.044703   5.380445   \n",
       " 10   KNeighborsDist_BAG_L1   0.439701       0.101992   0.007524   \n",
       " 11   KNeighborsUnif_BAG_L1   0.430521       0.102279   0.012836   \n",
       " \n",
       "     pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       " 0                 0.000459           0.292907            2       True   \n",
       " 1                 0.043343           6.216748            1       True   \n",
       " 2                 0.018260           3.948749            1       True   \n",
       " 3                 0.035997           4.784703            1       True   \n",
       " 4                 0.080397           0.497983            1       True   \n",
       " 5                 0.154725           8.174526            1       True   \n",
       " 6                 1.297920          37.008252            1       True   \n",
       " 7                 0.043935           6.733270            1       True   \n",
       " 8                 0.078450           0.604437            1       True   \n",
       " 9                 0.044703           5.380445            1       True   \n",
       " 10                0.101992           0.007524            1       True   \n",
       " 11                0.102279           0.012836            1       True   \n",
       " \n",
       "     fit_order  \n",
       " 0          12  \n",
       " 1           3  \n",
       " 2           6  \n",
       " 3           4  \n",
       " 4           7  \n",
       " 5           8  \n",
       " 6          10  \n",
       " 7          11  \n",
       " 8           5  \n",
       " 9           9  \n",
       " 10          2  \n",
       " 11          1  }"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output the fit summary of the training run\n",
    "predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: r2 on test data: 0.3234147656720182\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"r2\": 0.3234147656720182,\n",
      "    \"root_mean_squared_error\": -58.90228952098435,\n",
      "    \"mean_squared_error\": -3469.4797108138628,\n",
      "    \"mean_absolute_error\": -44.49091399117802,\n",
      "    \"pearsonr\": 0.5859114189286458,\n",
      "    \"median_absolute_error\": -36.467437744140625\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the models performance on the test dataset\n",
    "performance = predictor.evaluate(dfd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
